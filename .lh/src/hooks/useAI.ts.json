{
    "sourceFile": "src/hooks/useAI.ts",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 8,
            "patches": [
                {
                    "date": 1754643303926,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1754645302702,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,6 +1,6 @@\n import { useCallback, useRef, useState } from 'react'\n-import { getVertexAI, getGenerativeModel, GenerativeModel, ChatSession } from 'firebase/vertexai'\n+import { getVertexAI, getGenerativeModel, GenerativeModel, ChatSession } from 'firebase/ai'\n import { app } from '@/firebaseConfig'\n import { devLog } from '@/utils/devLogger'\n \n export type SimpleModel = 'gemini-2.5-flash' | 'gemini-2.0-flash' | 'gemini-1.5-flash'\n"
                },
                {
                    "date": 1754877427684,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,6 +1,6 @@\n import { useCallback, useRef, useState } from 'react'\n-import { getVertexAI, getGenerativeModel, GenerativeModel, ChatSession } from 'firebase/ai'\n+import { getAI, getGenerativeModel, GenerativeModel, ChatSession } from 'firebase/ai'\n import { app } from '@/firebaseConfig'\n import { devLog } from '@/utils/devLogger'\n \n export type SimpleModel = 'gemini-2.5-flash' | 'gemini-2.0-flash' | 'gemini-1.5-flash'\n@@ -12,10 +12,10 @@\n \n   const ensureModel = useCallback(() => {\n     if (!app) throw new Error('Firebase app not initialized')\n     if (!modelRef.current) {\n-      const vertexAI = getVertexAI(app)\n-      modelRef.current = getGenerativeModel(vertexAI, { model: modelName })\n+      const ai = getAI(app)\n+      modelRef.current = getGenerativeModel(ai, { model: modelName })\n       devLog('[useAI] model initialized:', modelName)\n     }\n     return modelRef.current\n   }, [modelName])\n"
                },
                {
                    "date": 1754881386652,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -2,9 +2,16 @@\n import { getAI, getGenerativeModel, GenerativeModel, ChatSession } from 'firebase/ai'\n import { app } from '@/firebaseConfig'\n import { devLog } from '@/utils/devLogger'\n \n-export type SimpleModel = 'gemini-2.5-flash' | 'gemini-2.0-flash' | 'gemini-1.5-flash'\n+export type SimpleModel =\n+  | 'gemini-2.5-flash'\n+  | 'gemini-2.5-flash-lite'\n+  | 'gemini-2.0-flash'\n+  | 'gemini-2.0-flash-lite'\n+  | 'gemini-1.5-flash'\n+  | 'gemini-1.5-flash-8b'\n+  | (string & {}) // 사용자가 직접 입력한 모델명 허용\n \n export default function useAI(initialModel: SimpleModel = 'gemini-2.5-flash') {\n   const [modelName, setModelName] = useState<SimpleModel>(initialModel)\n   const modelRef = useRef<GenerativeModel | null>(null)\n@@ -19,17 +26,15 @@\n     }\n     return modelRef.current\n   }, [modelName])\n \n-  // 단발 프롬프트 → 텍스트 응답\n   const generate = useCallback(async (prompt: string): Promise<string> => {\n     const model = ensureModel()\n     const res = await model.generateContent(prompt)\n     const text = res.response.text()\n     return text\n   }, [ensureModel])\n \n-  // 채팅 세션 유지 응답\n   const sendChat = useCallback(async (message: string): Promise<string> => {\n     const model = ensureModel()\n     if (!chatRef.current) chatRef.current = model.startChat()\n     const res = await chatRef.current.sendMessage(message)\n@@ -39,6 +44,18 @@\n   const resetChat = useCallback(() => {\n     chatRef.current = null\n   }, [])\n \n-  return { modelName, setModelName, generate, sendChat, resetChat }\n+  const testModel = useCallback(async (): Promise<{ ok: boolean; message: string }> => {\n+    try {\n+      const model = ensureModel()\n+      const res = await model.generateContent('ping')\n+      const t = res.response.text()\n+      return { ok: true, message: t?.slice(0, 160) || 'OK' }\n+    } catch (e: any) {\n+      const msg = e?.message || String(e)\n+      return { ok: false, message: msg }\n+    }\n+  }, [ensureModel])\n+\n+  return { modelName, setModelName, generate, sendChat, resetChat, testModel }\n }\n"
                },
                {
                    "date": 1754885157182,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -6,11 +6,8 @@\n export type SimpleModel =\n   | 'gemini-2.5-flash'\n   | 'gemini-2.5-flash-lite'\n   | 'gemini-2.0-flash'\n-  | 'gemini-2.0-flash-lite'\n-  | 'gemini-1.5-flash'\n-  | 'gemini-1.5-flash-8b'\n   | (string & {}) // 사용자가 직접 입력한 모델명 허용\n \n export default function useAI(initialModel: SimpleModel = 'gemini-2.5-flash') {\n   const [modelName, setModelName] = useState<SimpleModel>(initialModel)\n"
                },
                {
                    "date": 1754885480912,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -10,20 +10,22 @@\n   | (string & {}) // 사용자가 직접 입력한 모델명 허용\n \n export default function useAI(initialModel: SimpleModel = 'gemini-2.5-flash') {\n   const [modelName, setModelName] = useState<SimpleModel>(initialModel)\n+  const [systemInstruction, setSystemInstruction] = useState<string | undefined>(undefined)\n   const modelRef = useRef<GenerativeModel | null>(null)\n   const chatRef = useRef<ChatSession | null>(null)\n \n   const ensureModel = useCallback(() => {\n     if (!app) throw new Error('Firebase app not initialized')\n-    if (!modelRef.current) {\n-      const ai = getAI(app)\n-      modelRef.current = getGenerativeModel(ai, { model: modelName })\n-      devLog('[useAI] model initialized:', modelName)\n-    }\n+    const ai = getAI(app)\n+    modelRef.current = getGenerativeModel(ai, {\n+      model: modelName,\n+      ...(systemInstruction ? { systemInstruction } : {}),\n+    })\n+    devLog('[useAI] model initialized:', modelName)\n     return modelRef.current\n-  }, [modelName])\n+  }, [modelName, systemInstruction])\n \n   const generate = useCallback(async (prompt: string): Promise<string> => {\n     const model = ensureModel()\n     const res = await model.generateContent(prompt)\n@@ -41,8 +43,13 @@\n   const resetChat = useCallback(() => {\n     chatRef.current = null\n   }, [])\n \n+  const setSystem = useCallback((sys: string | undefined) => {\n+    setSystemInstruction(sys)\n+    chatRef.current = null // 시스템 변경 시 세션 재시작\n+  }, [])\n+\n   const testModel = useCallback(async (): Promise<{ ok: boolean; message: string }> => {\n     try {\n       const model = ensureModel()\n       const res = await model.generateContent('ping')\n@@ -53,6 +60,6 @@\n       return { ok: false, message: msg }\n     }\n   }, [ensureModel])\n \n-  return { modelName, setModelName, generate, sendChat, resetChat, testModel }\n+  return { modelName, setModelName, generate, sendChat, resetChat, testModel, setSystemInstruction: setSystem }\n }\n"
                },
                {
                    "date": 1754885972626,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -8,8 +8,24 @@\n   | 'gemini-2.5-flash-lite'\n   | 'gemini-2.0-flash'\n   | (string & {}) // 사용자가 직접 입력한 모델명 허용\n \n+function logUsage(where: string, anyResponse: unknown) {\n+  // firebase/ai 응답의 사용량 메타데이터 다양한 케이스 대응\n+  // res.response?.usageMetadata OR res.usageMetadata\n+  // 필드명: inputTokenCount/outputTokenCount/totalTokenCount 또는 inputTokens/outputTokens/totalTokens\n+  const r: any = anyResponse as any\n+  const usage = r?.response?.usageMetadata || r?.usageMetadata\n+  if (!usage) {\n+    devLog(`[useAI] ${where} usage: (no usage metadata)`, r)\n+    return\n+  }\n+  const input = usage.inputTokenCount ?? usage.inputTokens\n+  const output = usage.outputTokenCount ?? usage.outputTokens\n+  const total = usage.totalTokenCount ?? usage.totalTokens\n+  devLog(`[useAI] ${where} tokens → input: ${input}, output: ${output}, total: ${total}`, usage)\n+}\n+\n export default function useAI(initialModel: SimpleModel = 'gemini-2.5-flash') {\n   const [modelName, setModelName] = useState<SimpleModel>(initialModel)\n   const [systemInstruction, setSystemInstruction] = useState<string | undefined>(undefined)\n   const modelRef = useRef<GenerativeModel | null>(null)\n@@ -28,16 +44,18 @@\n \n   const generate = useCallback(async (prompt: string): Promise<string> => {\n     const model = ensureModel()\n     const res = await model.generateContent(prompt)\n+    logUsage('generate', res)\n     const text = res.response.text()\n     return text\n   }, [ensureModel])\n \n   const sendChat = useCallback(async (message: string): Promise<string> => {\n     const model = ensureModel()\n     if (!chatRef.current) chatRef.current = model.startChat()\n     const res = await chatRef.current.sendMessage(message)\n+    logUsage('sendChat', res)\n     return res.response.text()\n   }, [ensureModel])\n \n   const resetChat = useCallback(() => {\n@@ -52,8 +70,9 @@\n   const testModel = useCallback(async (): Promise<{ ok: boolean; message: string }> => {\n     try {\n       const model = ensureModel()\n       const res = await model.generateContent('ping')\n+      logUsage('testModel', res)\n       const t = res.response.text()\n       return { ok: true, message: t?.slice(0, 160) || 'OK' }\n     } catch (e: any) {\n       const msg = e?.message || String(e)\n"
                },
                {
                    "date": 1754886116268,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -6,24 +6,80 @@\n export type SimpleModel =\n   | 'gemini-2.5-flash'\n   | 'gemini-2.5-flash-lite'\n   | 'gemini-2.0-flash'\n-  | (string & {}) // 사용자가 직접 입력한 모델명 허용\n+  | (string & {})\n \n-function logUsage(where: string, anyResponse: unknown) {\n-  // firebase/ai 응답의 사용량 메타데이터 다양한 케이스 대응\n-  // res.response?.usageMetadata OR res.usageMetadata\n-  // 필드명: inputTokenCount/outputTokenCount/totalTokenCount 또는 inputTokens/outputTokens/totalTokens\n+// USD 단가(백오피스에서 ENV로 전역 기본을 바꾸거나, 아래 테이블을 보정하세요)\n+// 단위: USD per 1M tokens (추정치). 실단가는 프로젝트 정책에 맞게 조정 필요\n+const DEFAULT_PRICING_PER_MTOK_USD: Record<string, { input: number; output: number }> = {\n+  'gemini-2.5-flash': { input: 0.35, output: 0.53 },\n+  'gemini-2.5-flash-lite': { input: 0.1, output: 0.2 },\n+  'gemini-2.0-flash': { input: 0.2, output: 0.4 },\n+}\n+\n+function getGlobalUsdRates() {\n+  const defIn = Number(process.env.NEXT_PUBLIC_GEMINI_INPUT_PER_MTOK_USD || '')\n+  const defOut = Number(process.env.NEXT_PUBLIC_GEMINI_OUTPUT_PER_MTOK_USD || '')\n+  return {\n+    input: Number.isFinite(defIn) && defIn > 0 ? defIn : undefined,\n+    output: Number.isFinite(defOut) && defOut > 0 ? defOut : undefined,\n+  }\n+}\n+\n+function getPricingForModel(modelName: string) {\n+  const global = getGlobalUsdRates()\n+  const table = DEFAULT_PRICING_PER_MTOK_USD[modelName]\n+  return {\n+    input: global.input ?? table?.input ?? 0.2,\n+    output: global.output ?? table?.output ?? 0.6,\n+  }\n+}\n+\n+function getUsdKrwRate() {\n+  const env = Number(process.env.NEXT_PUBLIC_USD_KRW || '')\n+  return Number.isFinite(env) && env > 0 ? env : 1350 // 기본 1350원/USD\n+}\n+\n+function formatCurrencyUSD(v: number) {\n+  return `$${v.toFixed(4)}`\n+}\n+function formatCurrencyKRW(v: number) {\n+  // 원 단위 반올림\n+  return `₩${Math.round(v).toLocaleString('ko-KR')}`\n+}\n+\n+function logUsageAndCost(where: string, modelName: string, anyResponse: unknown) {\n   const r: any = anyResponse as any\n   const usage = r?.response?.usageMetadata || r?.usageMetadata\n   if (!usage) {\n     devLog(`[useAI] ${where} usage: (no usage metadata)`, r)\n     return\n   }\n-  const input = usage.inputTokenCount ?? usage.inputTokens\n-  const output = usage.outputTokenCount ?? usage.outputTokens\n-  const total = usage.totalTokenCount ?? usage.totalTokens\n-  devLog(`[useAI] ${where} tokens → input: ${input}, output: ${output}, total: ${total}`, usage)\n+  const inputT = usage.inputTokenCount ?? usage.inputTokens ?? 0\n+  const outputT = usage.outputTokenCount ?? usage.outputTokens ?? 0\n+  const totalT = usage.totalTokenCount ?? usage.totalTokens ?? inputT + outputT\n+\n+  const rate = getPricingForModel(modelName)\n+  const usdKrw = getUsdKrwRate()\n+\n+  const inputCostUSD = (inputT / 1_000_000) * rate.input\n+  const outputCostUSD = (outputT / 1_000_000) * rate.output\n+  const totalCostUSD = inputCostUSD + outputCostUSD\n+\n+  const inputCostKRW = inputCostUSD * usdKrw\n+  const outputCostKRW = outputCostUSD * usdKrw\n+  const totalCostKRW = totalCostUSD * usdKrw\n+\n+  devLog(\n+    `[useAI] ${where} tokens → input: ${inputT}, output: ${outputT}, total: ${totalT}`\n+  )\n+  devLog(\n+    `[useAI] ${where} cost(USD) → input: ${formatCurrencyUSD(inputCostUSD)}, output: ${formatCurrencyUSD(outputCostUSD)}, total: ${formatCurrencyUSD(totalCostUSD)}`\n+  )\n+  devLog(\n+    `[useAI] ${where} cost(KRW) → input: ${formatCurrencyKRW(inputCostKRW)}, output: ${formatCurrencyKRW(outputCostKRW)}, total: ${formatCurrencyKRW(totalCostKRW)}  (FX: ${usdKrw.toLocaleString('ko-KR')} KRW/USD)`\n+  )\n }\n \n export default function useAI(initialModel: SimpleModel = 'gemini-2.5-flash') {\n   const [modelName, setModelName] = useState<SimpleModel>(initialModel)\n@@ -44,20 +100,20 @@\n \n   const generate = useCallback(async (prompt: string): Promise<string> => {\n     const model = ensureModel()\n     const res = await model.generateContent(prompt)\n-    logUsage('generate', res)\n+    logUsageAndCost('generate', String(modelName), res)\n     const text = res.response.text()\n     return text\n-  }, [ensureModel])\n+  }, [ensureModel, modelName])\n \n   const sendChat = useCallback(async (message: string): Promise<string> => {\n     const model = ensureModel()\n     if (!chatRef.current) chatRef.current = model.startChat()\n     const res = await chatRef.current.sendMessage(message)\n-    logUsage('sendChat', res)\n+    logUsageAndCost('sendChat', String(modelName), res)\n     return res.response.text()\n-  }, [ensureModel])\n+  }, [ensureModel, modelName])\n \n   const resetChat = useCallback(() => {\n     chatRef.current = null\n   }, [])\n@@ -70,15 +126,15 @@\n   const testModel = useCallback(async (): Promise<{ ok: boolean; message: string }> => {\n     try {\n       const model = ensureModel()\n       const res = await model.generateContent('ping')\n-      logUsage('testModel', res)\n+      logUsageAndCost('testModel', String(modelName), res)\n       const t = res.response.text()\n       return { ok: true, message: t?.slice(0, 160) || 'OK' }\n     } catch (e: any) {\n       const msg = e?.message || String(e)\n       return { ok: false, message: msg }\n     }\n-  }, [ensureModel])\n+  }, [ensureModel, modelName])\n \n   return { modelName, setModelName, generate, sendChat, resetChat, testModel, setSystemInstruction: setSystem }\n }\n"
                },
                {
                    "date": 1754886405059,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -47,32 +47,55 @@\n   // 원 단위 반올림\n   return `₩${Math.round(v).toLocaleString('ko-KR')}`\n }\n \n+function pickNumber(...vals: any[]) {\n+  for (const v of vals) {\n+    if (typeof v === 'number' && Number.isFinite(v)) return v\n+  }\n+  return 0\n+}\n+\n function logUsageAndCost(where: string, modelName: string, anyResponse: unknown) {\n   const r: any = anyResponse as any\n   const usage = r?.response?.usageMetadata || r?.usageMetadata\n   if (!usage) {\n     devLog(`[useAI] ${where} usage: (no usage metadata)`, r)\n     return\n   }\n-  const inputT = usage.inputTokenCount ?? usage.inputTokens ?? 0\n-  const outputT = usage.outputTokenCount ?? usage.outputTokens ?? 0\n-  const totalT = usage.totalTokenCount ?? usage.totalTokens ?? inputT + outputT\n+  // 문서 기준 필드 대응\n+  const promptT = pickNumber(\n+    usage.promptTokenCount,\n+    usage.inputTokenCount,\n+    usage.inputTokens\n+  )\n+  const candidatesT = pickNumber(\n+    usage.candidatesTokenCount,\n+    usage.outputTokenCount,\n+    usage.outputTokens\n+  )\n+  const cachedT = pickNumber(usage.cachedContentTokenCount)\n+  const thoughtsT = pickNumber(usage.thoughtsTokenCount)\n+  const totalT = pickNumber(\n+    usage.totalTokenCount,\n+    usage.totalTokens,\n+    promptT + candidatesT // fallback\n+  )\n \n   const rate = getPricingForModel(modelName)\n   const usdKrw = getUsdKrwRate()\n \n-  const inputCostUSD = (inputT / 1_000_000) * rate.input\n-  const outputCostUSD = (outputT / 1_000_000) * rate.output\n+  // 비용 계산은 입력/출력 기준으로만 산정 (캐시/생각 토큰은 별도 표기)\n+  const inputCostUSD = (promptT / 1_000_000) * rate.input\n+  const outputCostUSD = (candidatesT / 1_000_000) * rate.output\n   const totalCostUSD = inputCostUSD + outputCostUSD\n \n   const inputCostKRW = inputCostUSD * usdKrw\n   const outputCostKRW = outputCostUSD * usdKrw\n   const totalCostKRW = totalCostUSD * usdKrw\n \n   devLog(\n-    `[useAI] ${where} tokens → input: ${inputT}, output: ${outputT}, total: ${totalT}`\n+    `[useAI] ${where} tokens → input(prompt): ${promptT}, output(candidates): ${candidatesT}, cached: ${cachedT}, thoughts: ${thoughtsT}, total: ${totalT}`\n   )\n   devLog(\n     `[useAI] ${where} cost(USD) → input: ${formatCurrencyUSD(inputCostUSD)}, output: ${formatCurrencyUSD(outputCostUSD)}, total: ${formatCurrencyUSD(totalCostUSD)}`\n   )\n"
                }
            ],
            "date": 1754643303926,
            "name": "Commit-0",
            "content": "import { useCallback, useRef, useState } from 'react'\nimport { getVertexAI, getGenerativeModel, GenerativeModel, ChatSession } from 'firebase/vertexai'\nimport { app } from '@/firebaseConfig'\nimport { devLog } from '@/utils/devLogger'\n\nexport type SimpleModel = 'gemini-2.5-flash' | 'gemini-2.0-flash' | 'gemini-1.5-flash'\n\nexport default function useAI(initialModel: SimpleModel = 'gemini-2.5-flash') {\n  const [modelName, setModelName] = useState<SimpleModel>(initialModel)\n  const modelRef = useRef<GenerativeModel | null>(null)\n  const chatRef = useRef<ChatSession | null>(null)\n\n  const ensureModel = useCallback(() => {\n    if (!app) throw new Error('Firebase app not initialized')\n    if (!modelRef.current) {\n      const vertexAI = getVertexAI(app)\n      modelRef.current = getGenerativeModel(vertexAI, { model: modelName })\n      devLog('[useAI] model initialized:', modelName)\n    }\n    return modelRef.current\n  }, [modelName])\n\n  // 단발 프롬프트 → 텍스트 응답\n  const generate = useCallback(async (prompt: string): Promise<string> => {\n    const model = ensureModel()\n    const res = await model.generateContent(prompt)\n    const text = res.response.text()\n    return text\n  }, [ensureModel])\n\n  // 채팅 세션 유지 응답\n  const sendChat = useCallback(async (message: string): Promise<string> => {\n    const model = ensureModel()\n    if (!chatRef.current) chatRef.current = model.startChat()\n    const res = await chatRef.current.sendMessage(message)\n    return res.response.text()\n  }, [ensureModel])\n\n  const resetChat = useCallback(() => {\n    chatRef.current = null\n  }, [])\n\n  return { modelName, setModelName, generate, sendChat, resetChat }\n}\n"
        }
    ]
}